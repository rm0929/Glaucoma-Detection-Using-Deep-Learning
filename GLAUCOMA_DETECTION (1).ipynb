{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import lite\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten,Dropout\n",
        "import PIL\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "PLxQskX_LyFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTVSG5__LsNW"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an additional column, mapping to the type\n",
        "df = pd.read_csv('a. IDRiD_Disease Grading_Training Labels.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_xOpmEWVL1zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.iloc[:,2:12],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "VtQm73-_L1xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "H6wtkOd9L1vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "diagnosis_dict_binary = {\n",
        "    0: 'No_DR',\n",
        "    1: 'DR',\n",
        "    2: 'DR',\n",
        "    3: 'DR',\n",
        "    4: 'DR'\n",
        "}\n",
        "\n",
        "diagnosis_dict = {\n",
        "    0: 'No_DR',\n",
        "    1: 'Mild',\n",
        "    2: 'Moderate',\n",
        "    3: 'Severe',\n",
        "    4: 'Proliferate_DR',\n",
        "}\n",
        "\n",
        "\n",
        "df['binary_type'] =  df['Retinopathy grade'].map(diagnosis_dict_binary.get)\n",
        "df['type'] = df['Retinopathy grade'].map(diagnosis_dict.get)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1pHnjRgbL1t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "UNgflic6L1sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "CFx8m5enL1rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mld=len(df[df['type']=='Mild'])\n",
        "sevr=len(df[df['type']=='Severe'])\n",
        "pdr=len(df[df['type']=='Proliferate_DR'])\n",
        "mdr=len(df[df['type']=='Moderate'])\n",
        "ndr=len(df[df['type']=='No_DR'])\n",
        "print(\"Retinopathy Grade:-   \\t\\tCount\")\n",
        "print(\"  -- Mild:- \\t\\t\\t\",mld)\n",
        "print(\"  -- Severe:- \\t\\t\\t\",sevr)\n",
        "print(\"  -- Proliferate_DR:- \\t\\t\",pdr)\n",
        "print(\"  -- Moderate:- \\t\\t\",mdr)\n",
        "print(\"  -- Non Glaucomatic(No_DR):- \\t\",ndr)"
      ],
      "metadata": {
        "id": "4Vsp5FfeL1p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "dDlqhDNaY5gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ( \"orange\", \"cyan\",\n",
        "          \"grey\", \"indigo\", \"beige\")\n",
        "\n",
        "df['type'].value_counts().plot(kind='pie',\n",
        "                               autopct='%1.1f%%',\n",
        "                               explode = (0.1, 0.0, 0.2, 0.3, 0.2),\n",
        "                               shadow = True,\n",
        "                               colors = colors,\n",
        "                               startangle = 90)"
      ],
      "metadata": {
        "id": "tnEResdDL1oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr=mld+sevr+pdr+mdr\n",
        "nodr=ndr\n",
        "print(\"DR vs NO_DR:-   \\t\\tCount\")\n",
        "print(\"  -- DR:- \\t\\t\\t\",dr)\n",
        "print(\"  -- NO_DR:- \\t\\t\\t\",nodr)"
      ],
      "metadata": {
        "id": "HWbJq88iL1mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['binary_type'].value_counts().plot(kind='barh',color=('orange','grey'))\n",
        "val=[]\n",
        "val.append(dr)\n",
        "val.append(nodr)\n",
        "for index,value in enumerate(val):\n",
        "    plt.text(value, index,str(value))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wys2ApkoL1lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_intermediate, val = train_test_split(df, test_size = 0.25, stratify = df['type'])\n",
        "train, test = train_test_split(train_intermediate, test_size = 0.25 / (1 - 0.25), stratify = train_intermediate['type'])\n",
        "\n",
        "print(train['type'].value_counts(), '\\n')\n",
        "print(test['type'].value_counts(), '\\n')\n",
        "print(val['type'].value_counts(), '\\n')\n",
        "# print(train.head())"
      ],
      "metadata": {
        "id": "cPov1gIeL1js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kpYXeuLuL1iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/gaussian_filtered_images/"
      ],
      "metadata": {
        "id": "PwkCrK_XL1gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir No_DR\n",
        "# !mkdir Mild\n",
        "# !mkdir Moderate\n",
        "# !mkdir Severe\n",
        "# !mkdir Proliferate_DR"
      ],
      "metadata": {
        "id": "tYQC5FinL1fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "g0UAxYiPL1dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "hkuMNa8wL1cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = os.getcwd()\n",
        "print(base_dir)"
      ],
      "metadata": {
        "id": "y-5GVotgL1aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create working directories for train/val/test\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "if os.path.exists(train_dir):\n",
        "    shutil.rmtree(train_dir)\n",
        "os.makedirs(train_dir)\n",
        "\n",
        "if os.path.exists(val_dir):\n",
        "    shutil.rmtree(val_dir)\n",
        "os.makedirs(val_dir)\n",
        "\n",
        "if os.path.exists(test_dir):\n",
        "    shutil.rmtree(test_dir)\n",
        "os.makedirs(test_dir)"
      ],
      "metadata": {
        "id": "OZW5Dmw3L1Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "suuJWz1PL1XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "5o18xd76L1Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "9gh0M_R6L1Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "kx_OqrNNL1S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = r'./'\n",
        "for index, row in train.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['Image name'] + \".jpg\"\n",
        "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
        "    dstfile = os.path.join(train_dir, binary_diagnosis)\n",
        "    os.makedirs(dstfile, exist_ok = True)\n",
        "    shutil.copy(srcfile, dstfile)\n",
        "\n",
        "for index, row in val.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['Image name'] + \".jpg\"\n",
        "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
        "    dstfile = os.path.join(val_dir, binary_diagnosis)\n",
        "    os.makedirs(dstfile, exist_ok = True)\n",
        "    shutil.copy(srcfile, dstfile)\n",
        "\n",
        "for index, row in test.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['Image name'] + \".jpg\"\n",
        "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
        "    dstfile = os.path.join(test_dir, binary_diagnosis)\n",
        "    os.makedirs(dstfile, exist_ok = True)\n",
        "    shutil.copy(srcfile, dstfile)"
      ],
      "metadata": {
        "id": "fo2-t4YML1Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'train'\n",
        "val_path = 'val'\n",
        "test_path = 'test'\n",
        "\n",
        "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224),batch_size=3, shuffle = True)\n",
        "val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224),batch_size=2, shuffle = True)\n",
        "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
      ],
      "metadata": {
        "id": "LNCAaQQXL1QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15,3))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plotImages(sample_training_images[:3])"
      ],
      "metadata": {
        "id": "Co-Zh_hIL1Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten,Dropout\n",
        "import PIL\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "zhWeV7eVPvvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(64, (4,4), padding=\"valid\", input_shape=(224,224,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(32, (3,3), padding=\"valid\", activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(16, (3,3), padding=\"valid\", activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(2, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_batches)"
      ],
      "metadata": {
        "id": "a-BAtRatPa4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "fJgcBDSBP5bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Plotting accuracy versus epoch\")\n",
        "plt.plot(history.history['acc'], label='accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "print(\"The model is being evaluated\")\n",
        "test_loss, test_acc = model.evaluate(test_batches, verbose=2)\n",
        "print(\"The accuracy of the model is:\")\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "9eVzukvqPas6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zY7Sh9OrPdLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESNET-**50**\n",
        "\n",
        "> Indented block\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ITR_Ih9c4gwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet50\n",
        "\n",
        "# resnet_model = Sequential()\n",
        "\n",
        "# pretrained_model = tf.keras.applications.ResNet50( include_top=False,\n",
        "#     weights='imagenet',\n",
        "#     # input_tensor=None,\n",
        "#     input_shape=(224,224,3),\n",
        "#     pooling='max',\n",
        "#     classes=2\n",
        "# )\n",
        "\n",
        "# for layer in pretrained_model.layers[-15:]:\n",
        "#   layer.trainable=False\n",
        "\n",
        "\n",
        "# resnet_model.add(pretrained_model)\n",
        "# resnet_model.add(Dropout(0.3))\n",
        "# resnet_model.add(Flatten())\n",
        "# resnet_model.add(Dense(64,activation='relu'))\n",
        "# resnet_model.add(Dense(2,activation='softmax'))\n"
      ],
      "metadata": {
        "id": "ezIuXbohL0-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet_model.summary()"
      ],
      "metadata": {
        "id": "s5ye5Gp6L08p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xe43ckYYL06U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = resnet_model.fit(train_batches,\n",
        "#                     epochs=50,\n",
        "#                     validation_data=val_batches\n",
        "#                     )"
      ],
      "metadata": {
        "id": "EP4lKlY0L037"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Plotting accuracy versus epoch\")\n",
        "# plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.ylim([0.5, 1])\n",
        "# plt.legend(loc='lower right')\n",
        "# print(\"The model is being evaluated\")\n",
        "# test_loss, test_acc = resnet_model.evaluate(val_batches, verbose=2)\n",
        "# print(\"The accuracy of the model is:\")\n",
        "# print(test_acc)"
      ],
      "metadata": {
        "id": "4NA49DKJlL4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG16**"
      ],
      "metadata": {
        "id": "CP5PnqQgxxcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_path = 'train'\n",
        "# val_path = 'val'\n",
        "# test_path = 'test'\n",
        "\n",
        "# train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224),batch_size=2, shuffle = True)\n",
        "# val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224),batch_size=2, shuffle = True)\n",
        "# test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
      ],
      "metadata": {
        "id": "n_GhO1ndx1zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  VGG16\n",
        "\n",
        "# from tensorflow.python.ops.gen_math_ops import Max\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# VGG_model=tf.keras.applications.VGG16(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(224,224,3),\n",
        "#     pooling='max',\n",
        "# )\n",
        "\n",
        "# for layer in VGG_model.layers[:-15]:\n",
        "#    layer.trainable=False\n",
        "\n",
        "# model.add(VGG_model)\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Dense(64,activation='relu'))\n",
        "# model.add(Dense(32,activation='relu'))\n",
        "# model.add(Dense(2,activation='softmax'))\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "4Iu-QlnCXDDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WF-5V6iN4cnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(train_batches,\n",
        "#                     epochs=30,\n",
        "#                     validation_data=val_batches\n",
        "#                     )"
      ],
      "metadata": {
        "id": "5CHalHkUxCEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Plotting accuracy versus epoch\")\n",
        "# plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.ylim([0, 2])\n",
        "# plt.legend(loc='lower right')\n",
        "# print(\"The model is being evaluated\")\n",
        "# test_loss, test_acc = model.evaluate(test_batches, verbose=2)\n",
        "# print(\"The accuracy of the model is:\")\n",
        "# print(test_acc)"
      ],
      "metadata": {
        "id": "-CRJGNUCb1Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XyA88tEa392D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN+VGG16 (Hybrid Model)"
      ],
      "metadata": {
        "id": "Nq7G0g08UALO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_path = 'train'\n",
        "# val_path = 'val'\n",
        "# test_path = 'test'\n",
        "\n",
        "# train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(580, 580),batch_size=3, shuffle = True)\n",
        "# val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(580, 580),batch_size=2, shuffle = True)\n",
        "# test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(580, 580), shuffle = False)"
      ],
      "metadata": {
        "id": "iKJNiHzG4AXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #CNN\n",
        "# #VGG16\n",
        "# from tensorflow.python.ops.gen_math_ops import Max\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (4, 4), input_shape = (580, 580,3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(16, (3, 3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(3, (3, 3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# VGG_model=tf.keras.applications.VGG16(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=( 70, 70, 3),\n",
        "#     pooling='max',\n",
        "# )\n",
        "\n",
        "# for layer in VGG_model.layers[:-15]:\n",
        "#    layer.trainable=False\n",
        "\n",
        "# model.add(VGG_model)\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64,activation='relu'))\n",
        "# model.add(Dense(32,activation='relu'))\n",
        "# model.add(Dense(2,activation='softmax'))\n",
        "# model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "PG6_5c2oAaeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4NWzueNJGMqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4eg8syJfGIcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(train_batches,\n",
        "#                     # epochs=30,\n",
        "#                     validation_data=val_batches\n",
        "#                     )"
      ],
      "metadata": {
        "id": "cNhfrDxYAacT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate()"
      ],
      "metadata": {
        "id": "bXy91VopScNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Plotting accuracy versus epoch\")\n",
        "# plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.ylim([0, 2])\n",
        "# plt.legend(loc='lower right')\n",
        "# print(\"The model is being evaluated\")\n",
        "# test_loss, test_acc = model.evaluate(test_batches, verbose=2)\n",
        "# print(\"The accuracy of the model is:\")\n",
        "# print(test_acc)"
      ],
      "metadata": {
        "id": "G9cfh_gaAaaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.python.ops.gen_math_ops import Max\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n"
      ],
      "metadata": {
        "id": "XNt4CY0VAaYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN+ResNet50 (Hybrid **Model**)"
      ],
      "metadata": {
        "id": "9dwuGZcYhpZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "\n",
        "# model.add(Conv2D(64, (4, 4), input_shape = (559,559,3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(32, (4, 4), input_shape = (274, 274,3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(16, (3, 3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(3, (3, 3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "#VGG16\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "\n",
        "# resnet_model = Sequential()\n",
        "# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "#                    input_shape=(224, 224, 3),\n",
        "#                    pooling='max',classes=2,\n",
        "#                    weights=\"imagenet\")\n",
        "# for layer in pretrained_model.layers[-15:]:\n",
        "#         layer.trainable=False\n",
        "\n",
        "# resnet_model.add(pretrained_model)\n",
        "\n",
        "# # resnet_model.summary()\n",
        "\n",
        "\n",
        "# # Merge\n",
        "# model.add(resnet_model)\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64,activation='relu'))\n",
        "# model.add(Dense(32,activation='relu'))\n",
        "# model.add(Dense(2,activation='softmax'))\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "rETpaDZjAaWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lT0TfnSN14eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_path = 'train'\n",
        "# val_path = 'val'\n",
        "# test_path = 'test'\n",
        "\n",
        "# train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224),batch_size=3, shuffle = True)\n",
        "# val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224),batch_size=2, shuffle = True)\n",
        "# test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
      ],
      "metadata": {
        "id": "WPpKyg2s16v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Conv2D(16, (4, 4), input_shape = (224,224,3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(3, (4, 4), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# vg_model=Sequential()\n",
        "# VGG_model=tf.keras.applications.VGG16(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=( 53, 53, 3),\n",
        "#     pooling='max',\n",
        "# )\n",
        "# for layer in VGG_model.layers[:-15]:\n",
        "#    layer.trainable=False\n",
        "# from tensorflow.keras import Model\n",
        "# vg_model.add(VGG_model)\n",
        "# vg_model.add(Dropout(0.4))\n",
        "# vg_model.add(Dense(units = 512, activation = 'relu'))\n",
        "# vg_model.add(Dense(units = 128, activation = 'relu'))\n",
        "# vg_model.add(Dense(units = 2,activation='softmax'))\n",
        "# out2 = vg_model(model.outputs)\n",
        "# m3 = Model(model.inputs,out2)\n",
        "# m3.summary()\n",
        "\n",
        "# #cnn+vgg"
      ],
      "metadata": {
        "id": "_WVBnkCszVRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MICKFLmgzVDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# m3.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vL1XvYPIAaOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IR3S3TnFjUQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = m3.fit(train_batches,\n",
        "#                     epochs=30,\n",
        "#                     validation_data=val_batches\n",
        "#                     )"
      ],
      "metadata": {
        "id": "3wGUKUJFAaK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Plotting accuracy versus epoch\")\n",
        "# plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.ylim([0, 2])\n",
        "# plt.legend(loc='lower right')\n",
        "# print(\"The model is being evaluated\")\n",
        "# test_loss, test_acc = m3.evaluate(test_batches, verbose=2)\n",
        "# print(\"The accuracy of the model is:\")\n",
        "# print(test_acc)"
      ],
      "metadata": {
        "id": "HqoVvwGUAaIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjb1u7DK2ZoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owRgKlXb2ZqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_path = 'train'\n",
        "# val_path = 'val'\n",
        "# test_path = 'test'\n",
        "\n",
        "# train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224),batch_size=3, shuffle = True)\n",
        "# val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224),batch_size=2, shuffle = True)\n",
        "# test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
      ],
      "metadata": {
        "id": "iVO23t0DEBJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers import TimeDistributed"
      ],
      "metadata": {
        "id": "H-nz-1uBJG_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Conv2D(16, (4, 4), input_shape = (224,224,3), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Conv2D(3, (4, 4), activation = 'relu'))\n",
        "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# model.add(Flatten())\n",
        "# # model.outputs[0].shape\n",
        "# lstm=Sequential()\n",
        "# lstm.add(TimeDistributed(model,))\n",
        "# lstm.add(LSTM(1024))\n",
        "# lstm.add(Dense(128))\n",
        "# lstm.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# lstm.build(224,224,1)\n",
        "# lstm.summary()"
      ],
      "metadata": {
        "id": "i6vZRjXbIGv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X=model.outputs[0].shape\n",
        "# X.reshape()"
      ],
      "metadata": {
        "id": "w1h0qresK7WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_gjlIAJ1IGzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESNET-**VGG**"
      ],
      "metadata": {
        "id": "CfrKyAn9OuOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_path = 'train'\n",
        "# val_path = 'val'\n",
        "# test_path = 'test'\n",
        "\n",
        "# train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224),batch_size=3, shuffle = True)\n",
        "# val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224),batch_size=2, shuffle = True)\n",
        "# test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
      ],
      "metadata": {
        "id": "heDMldrHOy8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# vg_model=Sequential()\n",
        "# VGG_model=tf.keras.applications.VGG16(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=( 900,900, 3),\n",
        "#     pooling='max',\n",
        "# )\n",
        "# for layer in VGG_model.layers[:-15]:\n",
        "#    layer.trainable=False\n",
        "# from tensorflow.keras import Model\n",
        "# vg_model.add(VGG_model)\n",
        "# # m3 = Model(model.inputs,out2)\n",
        "# # m3.summary()\n",
        "# vg_model.summary()"
      ],
      "metadata": {
        "id": "vLVNArjkOzmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # resnet_model = Sequential()\n",
        "# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "#                    input_shape=(900, 900, 3),\n",
        "#                    pooling='max',classes=2,\n",
        "#                    weights=\"imagenet\")\n",
        "# for layer in pretrained_model.layers[-10:]:\n",
        "#         layer.trainable=False\n",
        "\n",
        "# # resnet_model.add(pretrained_model)\n",
        "# pretrained_model.summary()"
      ],
      "metadata": {
        "id": "M8ouIZCsOzqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs_2 = keras.Input(shape=(224, 224, 3), name=\"img\")\n",
        "# vgg = tf.keras.applications.VGG16(input_tensor=inputs_2, weights='imagenet', include_top=False) #VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "# for layer in vgg.layers:\n",
        "#     layer.trainable = False\n",
        "# #x = Flatten()(vgg.output)\n",
        "\n",
        "# resnet = tf.keras.applications.ResNet50(input_tensor=inputs_2, weights='imagenet', include_top=False) #ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "# for layer in resnet.layers:\n",
        "#     layer.trainable = False\n",
        "# #y = Flatten()(resnet.output)\n",
        "\n",
        "# #concatenated_output= layers.add([x, y])\n",
        "# mergedOutput =  tf.keras.layers.Concatenate()([vgg.output, resnet.output])\n",
        "# x = layers.Dense(256, activation=\"relu\")(mergedOutput)\n",
        "# prediction = Dense(3, activation='softmax')(x)\n",
        "# model = Model(inputs=inputs_2, outputs=prediction)\n",
        "\n",
        "\n",
        "# model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "# # model.summary()"
      ],
      "metadata": {
        "id": "zKdsc9W4OzsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(train_batches,\n",
        "#                     epochs=30,\n",
        "#                     validation_data=val_batches\n",
        "#                     )"
      ],
      "metadata": {
        "id": "DTS9-tDJOzuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9pj_eUVOOzwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55a0Q7dbOzz3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}